{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please forgive some of the inefficient methods used!! Optimization takes more DSA knowledge than this!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task Graph Data Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class taskGraph:\n",
    "    # graph defined by no.of nodes, wcets of nodes and adjaceny matrix\n",
    "    def __init__(self,n,wcet,adj,m=1):\n",
    "        self.n=n\n",
    "        self.wcet=wcet\n",
    "        self.adj=adj\n",
    "        self.cores=m\n",
    "        # in adjacency matrix, adj[i][j]=1 if there is a edge from i -> j\n",
    "\n",
    "        # keep track of all the paths\n",
    "        self.paths=[]\n",
    "\n",
    "        #keep track of every parallel vertices for a given vertex\n",
    "        self.asc=[]\n",
    "        self.des=[]\n",
    "        self.par=[]\n",
    "\n",
    "        #len of longest path and volume of graph\n",
    "        self.len=0\n",
    "        self.vol=sum(self.wcet[i] for i in range(self.n))\n",
    "\n",
    "        #length of longest path through vertex i\n",
    "        self.l=[]\n",
    "\n",
    "    def simplePL(self):\n",
    "        p=[i for i in range(self.n)]\n",
    "        def cmp(a,b):\n",
    "            return self.l[a]>self.l[b] or (self.l[a]==self.l[b] and a<b)\n",
    "        p.sort(key=lambda x: -self.l[x])\n",
    "        return p\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_dag_with_weights(num_vertices, num_edges):\n",
    "    # Generate a random Directed Acyclic Graph\n",
    "    dag = nx.gnm_random_graph(num_vertices, num_edges, directed=True)\n",
    "\n",
    "    # Ensure the graph is a DAG\n",
    "    while not nx.is_directed_acyclic_graph(dag):\n",
    "        dag = nx.gnm_random_graph(num_vertices, num_edges, directed=True)\n",
    "\n",
    "    # Add a single source and sink\n",
    "    source = np.random.choice(list(dag.nodes))\n",
    "    sink = np.random.choice(list(dag.nodes - set([source])))\n",
    "    dag.add_edge(source, sink)\n",
    "\n",
    "    # Assign random weights to each vertex\n",
    "    weights = {node: np.random.randint(1, 10) for node in dag.nodes}\n",
    "    nx.set_node_attributes(dag, weights, 'weight')\n",
    "\n",
    "    return dag\n",
    "\n",
    "def adjacency_matrix_with_weights_from_dag(dag):\n",
    "    # Convert the DAG to an adjacency matrix with weights\n",
    "    adjacency_matrix = nx.to_numpy_array(dag, dtype=int, weight='weight')\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Number of vertices and edges in the DAG\n",
    "num_vertices = 8\n",
    "num_edges = 12  # Adjust the number of edges as needed\n",
    "\n",
    "# Generate a random DAG with a single source and sink and assign random weights\n",
    "random_dag_with_weights = generate_random_dag_with_weights(num_vertices, num_edges)\n",
    "\n",
    "# Generate and print the adjacency matrix with weights\n",
    "adjacency_matrix_with_weights = adjacency_matrix_with_weights_from_dag(random_dag_with_weights)\n",
    "\n",
    "print(\"Random DAG with Weights:\")\n",
    "print(\"Edges:\", random_dag_with_weights.edges)\n",
    "print(\"Node Weights:\", nx.get_node_attributes(random_dag_with_weights, 'weight'))\n",
    "print(\"\\nAdjacency Matrix with Weights:\")\n",
    "print(adjacency_matrix_with_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=num_vertices\n",
    "wcet=np.random.rand(n)\n",
    "adj=adjacency_matrix_with_weights\n",
    "\n",
    "m=2\n",
    "G=taskGraph(n,wcet,adj,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the descendents of each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_des_util(G:taskGraph,i:int,n:int,se:set):\n",
    "    if(i+1 in se):\n",
    "        return\n",
    "    for j in range(n):\n",
    "        if(G.adj[i][j]==1):\n",
    "            find_des_util(G,j,n,se)\n",
    "            se.add(j+1)\n",
    "    return\n",
    "\n",
    "def find_des(G:taskGraph,i:int,n:int):\n",
    "    se=set()\n",
    "    find_des_util(G,i-1,n,se)\n",
    "    return list(se)\n",
    "\n",
    "G.des.clear()\n",
    "for i in range(n):\n",
    "    ls=find_des(G,i+1,n)\n",
    "    G.des.append(ls.copy())\n",
    "print(G.des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the ascendents of each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_asc_util(G:taskGraph,i:int,n:int,se:set):\n",
    "    if(i+1 in se):\n",
    "        return\n",
    "    for j in range(n):\n",
    "        if(G.adj[j][i]==1):\n",
    "            find_asc_util(G,j,n,se)\n",
    "            se.add(j+1)\n",
    "    return\n",
    "\n",
    "def find_asc(G:taskGraph,i:int,n:int):\n",
    "    se=set()\n",
    "    find_asc_util(G,i-1,n,se)\n",
    "    return list(se)\n",
    "\n",
    "G.asc.clear()\n",
    "for i in range(n):\n",
    "    ls=find_asc(G,i+1,n)\n",
    "    G.asc.append(ls)\n",
    "\n",
    "print(G.asc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store parallel vertices of each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel(G:taskGraph,i:int,n:int):\n",
    "    ls=[]\n",
    "    for j in range(n):\n",
    "        if(i!=j and (j+1 not in G.des[i]) and (j+1 not in G.asc[i])):\n",
    "            ls.append(j+1)\n",
    "    return ls\n",
    "\n",
    "G.par.clear()\n",
    "for i in range(n):\n",
    "    G.par.append(parallel(G,i,n).copy())\n",
    "\n",
    "print(G.par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Paths Set ($\\Pi$) and calculate the length of longest path ($len$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathset(G:taskGraph,i:int,n:int,path:list):\n",
    "    k=0\n",
    "    for j in range(n):\n",
    "        if(G.adj[i][j]==1):\n",
    "            cp=path.copy()\n",
    "            cp.append(i+1)\n",
    "            pathset(G,j,n,cp)\n",
    "            k+=1\n",
    "    if(k==0):\n",
    "        cp=path.copy()\n",
    "        cp.append(i+1)\n",
    "        G.paths.append(cp)\n",
    "    \n",
    "pathset(G,0,n,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in G.paths:\n",
    "    pathlength=0\n",
    "    for node in path:\n",
    "        pathlength+=G.wcet[node-1]\n",
    "    G.len=max(G.len,pathlength)\n",
    "print(G.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the length of longest paths through each vertex $l(v_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,n+1):\n",
    "    G.l.append(0)\n",
    "    for path in G.paths:\n",
    "        if(i in path):\n",
    "            y=sum(G.wcet[j-1] for j in path)\n",
    "            G.l[i-1]=max(G.l[i-1],y)\n",
    "\n",
    "print(G.l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating WCRT bound $R_P(G)$ for given priority assignment $P$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that $R_P(G)$ is:\n",
    "\n",
    "$$R_P(G) = \\max_{\\pi_k \\in \\Pi}len(\\pi_k) + \\frac{vol(I_p(\\pi_k))}{m}$$\n",
    "\n",
    "Since the formula for WCRT bound of a critical path $\\pi_k$ under PLS algo with priority assignment $P$ is \n",
    "\n",
    "$$R_p(G,\\pi_k) = \\max_{\\pi_k \\in \\Pi}len(\\pi_k) + \\frac{vol(I_p(\\pi_k))}{m}$$\n",
    "\n",
    "What we are doing is just iterating over all the \"supposed\" critical paths which is pretty damn inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=[0,1,5,7,6,2,4,3]\n",
    "Ipset=set()\n",
    "for i in G.paths[2]:\n",
    "    for j in G.par[i-1]:\n",
    "        if(P[j-1]<P[i-1]):\n",
    "            Ipset.add(j)\n",
    "print(Ipset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcrt_inefficent(G:taskGraph,P:list):\n",
    "    # function to compute the worst case response time given Priority\n",
    "    R_max=0\n",
    "    path_max=[]\n",
    "    for path in G.paths:\n",
    "        ## Calculate length of path\n",
    "        length=sum(G.wcet[path[i]-1] for i in range(len(path)))\n",
    "\n",
    "        ## Calculate the Interference set....\n",
    "        Ip=set()\n",
    "        for i in path:\n",
    "            for j in G.par[i-1]:\n",
    "                if(P[j-1]<P[i-1]):\n",
    "                    Ip.add(j)\n",
    "\n",
    "        Ip=list(Ip)        \n",
    "        vol=sum(G.wcet[Ip[i]-1] for i in range(len(Ip)))\n",
    "\n",
    "        R=length+(vol/G.cores)\n",
    "\n",
    "        if(R>R_max):\n",
    "            R_max=R\n",
    "            path_max=path\n",
    "        \n",
    "    return R_max,path_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wcrt_inefficent(G,G.simplePL()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial priority assignment\n",
    "print(G.simplePL())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ILP Solver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laying down the formulation\n",
    "\n",
    "- ***Objective Function***: The objective function we want to <u>**minimize**</u> is:\n",
    "$R_P(G)$ for a given graph $G$ and varying over different priority assignments $P$ hence the problem being:\n",
    "    $$\\min_{P \\in P(G)} R_P(G)$$\n",
    "\n",
    "- ***Constraints***: \n",
    "    - $R$ constraints:\n",
    "        - $R \\geq  max\\{len,\\frac{vol}{m}\\}$\n",
    "        - $R \\geq \\sum_{v_i \\in V} w_{i}^k  \\;\\;\\; \\forall \\pi_k \\in \\Pi$\n",
    "\n",
    "    - Weight constraints:\n",
    "        - $w_{k}^i \\geq c(v_i) \\;\\;\\; \\forall v_i \\in \\pi_k \\;\\;\\; \\forall \\pi_k \\in \\Pi$   (For the nodes in critical path)\n",
    "        - $w_{k}^i \\geq 0 \\;\\;\\; \\forall v_i \\in V$ \n",
    "        -  $\\forall v_i \\notin \\pi_k, v_j \\in par_k(v_i)\\;\\;\\; \\forall \\pi_k \\in \\Pi$:\n",
    "            - $w_{k}^i \\geq \\frac{c(v_i)}{m} - M \\times y_{ij} ^ 1$\n",
    "            - $p_i \\leq p_j + M \\times y_{ij}^1 $\n",
    "            - $p_j < p_i + M \\times y_{ij}^2$\n",
    "            - $y_{ij}^1 + y_{ij}^2 = 1$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model=gp.Model(name=\"ILP_Solver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=opt_model.addVars(G.n,vtype=gp.GRB.INTEGER,lb=0,name=\"p\")\n",
    "R=opt_model.addVar(vtype=gp.GRB.CONTINUOUS,lb=max(G.len,G.vol/G.cores),name=\"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=[]\n",
    "y2=[]\n",
    "for i in range(G.n):\n",
    "    y1.append([])\n",
    "    y2.append([])\n",
    "    for j in range(G.n):\n",
    "        y1[i].append(opt_model.addVar(vtype=gp.GRB.BINARY,name=\"y1_%d_%d\" %(i,j)))\n",
    "        y2[i].append(opt_model.addVar(vtype=gp.GRB.BINARY,name=\"y2_%d_%d\" %(i,j)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model.update()\n",
    "obj_fn=R\n",
    "opt_model.setObjective(obj_fn,gp.GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremetal Update Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_update_ilp(G:taskGraph):\n",
    "    Pcb=None\n",
    "    Rcb=1e10\n",
    "     \n",
    "    pi_dash=[]\n",
    "    Pr=G.simplePL()     # done according to another paper. this method is just heuristic.\n",
    "    Rn,pi=wcrt_inefficent(G,Pr)\n",
    "    while(Rn<Rcb):\n",
    "        RpG,pi=wcrt_inefficent(G,Pr)\n",
    "        if(RpG<Rcb):\n",
    "            Rcb=RpG\n",
    "            Pcb=Pr\n",
    "        \n",
    "        if(pi in pi_dash):\n",
    "            return Pcb,Rcb\n",
    "        else:\n",
    "            pi_dash.append(pi)\n",
    "\n",
    "            wts.append([])\n",
    "            k=len(wts)-1\n",
    "            for i in range(G.n):\n",
    "                wts[k].append(opt_model.addVar(vtype=gp.GRB.CONTINUOUS,lb=0,name='w_%d_%d'%(k,i)))\n",
    "\n",
    "            opt_model.addConstr(R>=sum(wts[k][i] for i in range(G.n)))\n",
    "            for i in range(G.n):\n",
    "                if(i+1 in path):\n",
    "                    opt_model.addConstr(wts[k][i]>=G.wcet[i])\n",
    "                else:\n",
    "                    for j in path:\n",
    "                        if(j in G.par[i]):\n",
    "                            eps=0.00001\n",
    "                            opt_model.addConstr(wts[k][i]>=(G.wcet[i]/G.cores)-M*y1[i][j-1])\n",
    "                            opt_model.addConstr(p[j-1]<=p[i]+M*y1[i][j-1])\n",
    "                            opt_model.addConstr(p[i]<=p[j-1]+M*y2[i][j-1]-eps)\n",
    "                            opt_model.addConstr(y1[i][j-1]+y2[i][j-1]==1)\n",
    "            \n",
    "            opt_model.update()\n",
    "            opt_model.optimize()\n",
    "\n",
    "            Rn=opt_model.objVal\n",
    "            Pr=[opt_model.getVarByName(\"p[%d]\" % i).x for i in range(G.n)]\n",
    "    \n",
    "    return Pcb,Rcb\n",
    "            \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inc_update_ilp(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs637",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
